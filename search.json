[
  {
    "objectID": "shell.html",
    "href": "shell.html",
    "title": "shell source",
    "section": "",
    "text": "Exported source\nimport ast, time, signal, traceback\nfrom fastcore.utils import *\n\n\nget_shell is like python, except it also maintains a stateful interpreter, rather than just running a single line of code. This is implemented using IPython, so that must be installed.\n\n\nExported source\nfrom IPython.terminal.interactiveshell import TerminalInteractiveShell\nfrom IPython.utils.capture import capture_output\n\n\n\ndef exception2str(ex:Exception)-&gt;str:\n    \"Convert exception `ex` into a string\"\n    return ''.join(traceback.format_exception(type(ex), ex, ex.__traceback__))\n\n\ntry: print(1/0)\nexcept Exception as e: print(exception2str(e))\n\nTraceback (most recent call last):\n  File \"/var/folders/ss/34z569j921v58v8n1n_8z7h40000gn/T/ipykernel_37260/4058275565.py\", line 1, in &lt;module&gt;\n    try: print(1/0)\n               ~^~\nZeroDivisionError: division by zero\n\n\n\n\nsource\n\nTerminalInteractiveShell.run_cell\n\n TerminalInteractiveShell.run_cell (cell, timeout=None)\n\nWrapper for original run_cell which adds timeout and output capture\n\n\nExported source\nTerminalInteractiveShell.orig_run = TerminalInteractiveShell.run_cell\n\n\n\n\nExported source\n@patch\ndef run_cell(self:TerminalInteractiveShell, cell, timeout=None):\n    \"Wrapper for original `run_cell` which adds timeout and output capture\"\n    if timeout:\n        def handler(*args): raise TimeoutError()\n        signal.signal(signal.SIGALRM, handler)\n        signal.alarm(timeout)\n    try:\n        with capture_output() as io: result = self.orig_run(cell)\n        result.stdout = io.stdout\n        return result\n    except TimeoutException as e:\n        result = self.ExecutionResult(error_before_exec=None, error_in_exec=e)\n    finally:\n        if timeout: signal.alarm(0)\n\n\n\nsource\n\n\nget_shell\n\n get_shell ()\n\nGet a TerminalInteractiveShell with minimal functionality\n\n\nExported source\ndef get_shell()-&gt;TerminalInteractiveShell:\n    \"Get a `TerminalInteractiveShell` with minimal functionality\"\n    sh = TerminalInteractiveShell()\n    sh.logger.log_output = sh.history_manager.enabled = False\n    dh = sh.displayhook\n    dh.finish_displayhook = dh.write_output_prompt = dh.start_displayhook = lambda: None\n    dh.write_format_data = lambda format_dict, md_dict=None: None\n    sh.logstart = sh.automagic = sh.autoindent = False\n    sh.autocall = 0\n    sh.system = lambda cmd: None\n    return sh\n\n\n\nshell = get_shell()\n\n\nr = shell.run_cell('print(3); 1+1')\nr.result,r.stdout\n\n(2, '3\\n')\n\n\n\nr = shell.run_cell('raise Exception(\"blah\")')\nprint(exception2str(r.error_in_exec))\n\nTraceback (most recent call last):\n  File \"/Users/jhoward/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"&lt;ipython-input-1-338156281413&gt;\", line 1, in &lt;module&gt;\n    raise Exception(\"blah\")\nException: blah\n\n\n\n\nr = shell.run_cell('import time; time.sleep(10)', timeout=1)\nr.error_in_exec\n\nTimeoutError()",
    "crumbs": [
      "shell source"
    ]
  },
  {
    "objectID": "funccall.html",
    "href": "funccall.html",
    "title": "funccall source",
    "section": "",
    "text": "Exported source\nimport inspect\nfrom fastcore.utils import *\nfrom fastcore.docments import docments",
    "crumbs": [
      "funccall source"
    ]
  },
  {
    "objectID": "funccall.html#function-calling",
    "href": "funccall.html#function-calling",
    "title": "funccall source",
    "section": "Function calling",
    "text": "Function calling\nMany LLMs do function calling (aka tool use) by taking advantage of JSON schema.\nWe’ll use docments to make getting JSON schema from Python functions as ergonomic as possible. Each parameter (and the return value) should have a type, and a docments comment with the description of what it is. Here’s an example:\n\ndef silly_sum(\n    a:int, # First thing to sum\n    b:int=1, # Second thing to sum\n    c:list[int]=None, # A pointless argument\n) -&gt; int: # The sum of the inputs\n    \"Adds a + b.\"\n    return a + b\n\nThis is what docments makes of that:\n\nd = docments(silly_sum, full=True)\nd\n\n{ 'a': { 'anno': &lt;class 'int'&gt;,\n         'default': &lt;class 'inspect._empty'&gt;,\n         'docment': 'First thing to sum'},\n  'b': {'anno': &lt;class 'int'&gt;, 'default': 1, 'docment': 'Second thing to sum'},\n  'c': {'anno': list[int], 'default': None, 'docment': 'A pointless argument'},\n  'return': { 'anno': &lt;class 'int'&gt;,\n              'default': &lt;class 'inspect._empty'&gt;,\n              'docment': 'The sum of the inputs'}}\n\n\nNote that this is an AttrDict so we can treat it like an object, or a dict:\n\nd.a.docment, d['a']['anno']\n\n('First thing to sum', int)\n\n\n\n\nExported source\ndef _types(t:type)-&gt;tuple[str,Optional[str]]:\n    \"Tuple of json schema type name and (if appropriate) array item name.\"\n    if t is empty: raise TypeError('Missing type')\n    tmap = {int:\"integer\", float:\"number\", str:\"string\", bool:\"boolean\", list:\"array\", dict:\"object\"}\n    if getattr(t, '__origin__', None) in  (list,tuple): return \"array\", tmap.get(t.__args__[0], \"object\")\n    else: return tmap[t], None\n\n\nThis internal function is needed to convert Python types into JSON schema types.\n\n_types(list[int]), _types(int)\n\n(('array', 'integer'), ('integer', None))\n\n\n\n\nExported source\ndef _param(name, info):\n    \"json schema parameter given `name` and `info` from docments full dict.\"\n    paramt,itemt = _types(info.anno)\n    pschema = dict(type=paramt, description=info.docment or \"\")\n    if itemt: pschema[\"items\"] = {\"type\": itemt}\n    if info.default is not empty: pschema[\"default\"] = info.default\n    return pschema\n\n\nThis private function converts a key/value pair from the docments structure into the dict that will be needed for the schema.\n\nn,o = first(d.items())\nprint(n,'//', o)\n_param(n, o)\n\na // {'docment': 'First thing to sum', 'anno': &lt;class 'int'&gt;, 'default': &lt;class 'inspect._empty'&gt;}\n\n\n{'type': 'integer', 'description': 'First thing to sum'}\n\n\n\nsource\n\nget_schema\n\n get_schema (f:&lt;built-infunctioncallable&gt;, pname='input_schema')\n\nConvert function f into a JSON schema dict for tool use.\n\n\nExported source\ndef get_schema(f:callable, pname='input_schema')-&gt;dict:\n    \"Convert function `f` into a JSON schema `dict` for tool use.\"\n    d = docments(f, full=True)\n    ret = d.pop('return')\n    d.pop('self', None) # Ignore `self` for methods\n    paramd = {\n        'type': \"object\",\n        'properties': {n:_param(n,o) for n,o in d.items() if n[0]!='_'},\n        'required': [n for n,o in d.items() if o.default is empty and n[0]!='_']\n    }\n    desc = f.__doc__\n    assert desc, \"Docstring missing!\"\n    if ret.anno is not empty: desc += f'\\n\\nReturns:\\n- type: {_types(ret.anno)[0]}'\n    if ret.docment: desc += f'\\n- description: {ret.docment}'\n    return {'name':f.__name__, 'description':desc, pname:paramd}\n\n\nPutting this all together, we can now test getting a schema from silly_sum. The tool use spec doesn’t support return annotations directly, so we put that in the description instead.\n\ns = get_schema(silly_sum)\ndesc = s.pop('description')\nprint(desc)\ns\n\nAdds a + b.\n\nReturns:\n- type: integer\n- description: The sum of the inputs\n\n\n{'name': 'silly_sum',\n 'input_schema': {'type': 'object',\n  'properties': {'a': {'type': 'integer', 'description': 'First thing to sum'},\n   'b': {'type': 'integer',\n    'description': 'Second thing to sum',\n    'default': 1},\n   'c': {'type': 'array',\n    'description': 'A pointless argument',\n    'items': {'type': 'integer'},\n    'default': None}},\n  'required': ['a']}}\n\n\n\n\nPython tool\nIn language model clients it’s often useful to have a ‘code interpreter’ – this is something that runs code, and generally outputs the result of the last expression (i.e like IPython or Jupyter).\nIn this section we’ll create the python function, which executes a string as Python code, with an optional timeout. If the last line is an expression, we’ll return that – just like in IPython or Jupyter, but without needing them installed.\n\n\nExported source\nimport ast, time, signal, traceback\nfrom fastcore.utils import *\n\n\n\n\nExported source\ndef _copy_loc(new, orig):\n    \"Copy location information from original node to new node and all children.\"\n    new = ast.copy_location(new, orig)\n    for field, o in ast.iter_fields(new):\n        if isinstance(o, ast.AST): setattr(new, field, _copy_loc(o, orig))\n        elif isinstance(o, list): setattr(new, field, [_copy_loc(value, orig) for value in o])\n    return new\n\n\nThis is an internal function that’s needed for _run to ensure that location information is available in the abstract syntax tree (AST), since otherwise python complains.\n\n\nExported source\ndef _run(code:str ):\n    \"Run `code`, returning final expression (similar to IPython)\"\n    tree = ast.parse(code)\n    last_node = tree.body[-1] if tree.body else None\n    \n    # If the last node is an expression, modify the AST to capture the result\n    if isinstance(last_node, ast.Expr):\n        tgt = [ast.Name(id='_result', ctx=ast.Store())]\n        assign_node = ast.Assign(targets=tgt, value=last_node.value)\n        tree.body[-1] = _copy_loc(assign_node, last_node)\n\n    compiled_code = compile(tree, filename='&lt;ast&gt;', mode='exec')\n    namespace = {}\n    stdout_buffer = io.StringIO()\n    saved_stdout = sys.stdout\n    sys.stdout = stdout_buffer\n    try: exec(compiled_code, namespace)\n    finally: sys.stdout = saved_stdout\n    _result = namespace.get('_result', None)\n    if _result is not None: return _result\n    return stdout_buffer.getvalue().strip()\n\n\nThis is the internal function used to actually run the code – we pull off the last AST to see if it’s an expression (i.e something that returns a value), and if so, we store it to a special _result variable so we can return it.\n\n_run('import math;math.factorial(12)')\n\n479001600\n\n\n\n_run('print(1+1)')\n\n'2'\n\n\nWe now have the machinery needed to create our python function.\n\nsource\n\n\npython\n\n python (code, timeout=5)\n\nExecutes python code with timeout and returning final expression (similar to IPython). Raised exceptions are returned as a string, with a stack trace.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncode\n\n\nCode to execute\n\n\ntimeout\nint\n5\nMaximum run time in seconds before a TimeoutError is raised\n\n\n\n\n\nExported source\ndef python(code, # Code to execute\n           timeout=5 # Maximum run time in seconds before a `TimeoutError` is raised\n          ): # Result of last node, if it's an expression, or `None` otherwise\n    \"\"\"Executes python `code` with `timeout` and returning final expression (similar to IPython).\n    Raised exceptions are returned as a string, with a stack trace.\"\"\"\n    def handler(*args): raise TimeoutError()\n    signal.signal(signal.SIGALRM, handler)\n    signal.alarm(timeout)\n    try: return _run(code)\n    except Exception as e: return traceback.format_exc()\n    finally: signal.alarm(0)\n\n\nThere’s no builtin security here – you should generally use this in a sandbox, or alternatively prompt before running code. It can handle multiline function definitions, and pretty much any other normal Python syntax.\n\npython(\"\"\"def factorial(n):\n    if n == 0 or n == 1: return 1\n    else: return n * factorial(n-1)\nfactorial(5)\"\"\")\n\n120\n\n\nIf the code takes longer than timeout then it raises a TimeoutError.\n\ntry: python('import time; time.sleep(10)', timeout=1)\nexcept TimeoutError: print('Timed out')",
    "crumbs": [
      "funccall source"
    ]
  },
  {
    "objectID": "CHANGELOG.html",
    "href": "CHANGELOG.html",
    "title": "Release notes",
    "section": "",
    "text": "Rename project\n\n\n\n\n\nInitial alpha release"
  },
  {
    "objectID": "CHANGELOG.html#section",
    "href": "CHANGELOG.html#section",
    "title": "Release notes",
    "section": "",
    "text": "Rename project"
  },
  {
    "objectID": "CHANGELOG.html#section-1",
    "href": "CHANGELOG.html#section-1",
    "title": "Release notes",
    "section": "",
    "text": "Initial alpha release"
  },
  {
    "objectID": "xml.html",
    "href": "xml.html",
    "title": "xml source",
    "section": "",
    "text": "source\n\n\n\n json_to_xml (d:dict, rnm:str)\n\nConvert d to XML.\n\n\n\n\nType\nDetails\n\n\n\n\nd\ndict\nJSON dictionary to convert\n\n\nrnm\nstr\nRoot name\n\n\nReturns\nstr\n\n\n\n\n\n\nExported source\ndef json_to_xml(d:dict, # JSON dictionary to convert\n                rnm:str # Root name\n               )-&gt;str:\n    \"Convert `d` to XML.\"\n    root = ET.Element(rnm)\n    def build_xml(data, parent):\n        if isinstance(data, dict):\n            for key, value in data.items(): build_xml(value, ET.SubElement(parent, key))\n        elif isinstance(data, list):\n            for item in data: build_xml(item, ET.SubElement(parent, 'item'))\n        else: parent.text = str(data)\n    build_xml(d, root)\n    ET.indent(root)\n    return ET.tostring(root, encoding='unicode')\n\n\nJSON doesn’t map as nicely to XML as the data structure used in fastcore.xml, but for simple XML trees it can be convenient – for example:\n\na = dict(surname='Howard', firstnames=['Jeremy','Peter'],\n         address=dict(state='Queensland',country='Australia'))\nhl_md(json_to_xml(a, 'person'))\n\n&lt;person&gt;\n  &lt;surname&gt;Howard&lt;/surname&gt;\n  &lt;firstnames&gt;\n    &lt;item&gt;Jeremy&lt;/item&gt;\n    &lt;item&gt;Peter&lt;/item&gt;\n  &lt;/firstnames&gt;\n  &lt;address&gt;\n    &lt;state&gt;Queensland&lt;/state&gt;\n    &lt;country&gt;Australia&lt;/country&gt;\n  &lt;/address&gt;\n&lt;/person&gt;",
    "crumbs": [
      "xml source"
    ]
  },
  {
    "objectID": "xml.html#setup",
    "href": "xml.html#setup",
    "title": "xml source",
    "section": "",
    "text": "source\n\n\n\n json_to_xml (d:dict, rnm:str)\n\nConvert d to XML.\n\n\n\n\nType\nDetails\n\n\n\n\nd\ndict\nJSON dictionary to convert\n\n\nrnm\nstr\nRoot name\n\n\nReturns\nstr\n\n\n\n\n\n\nExported source\ndef json_to_xml(d:dict, # JSON dictionary to convert\n                rnm:str # Root name\n               )-&gt;str:\n    \"Convert `d` to XML.\"\n    root = ET.Element(rnm)\n    def build_xml(data, parent):\n        if isinstance(data, dict):\n            for key, value in data.items(): build_xml(value, ET.SubElement(parent, key))\n        elif isinstance(data, list):\n            for item in data: build_xml(item, ET.SubElement(parent, 'item'))\n        else: parent.text = str(data)\n    build_xml(d, root)\n    ET.indent(root)\n    return ET.tostring(root, encoding='unicode')\n\n\nJSON doesn’t map as nicely to XML as the data structure used in fastcore.xml, but for simple XML trees it can be convenient – for example:\n\na = dict(surname='Howard', firstnames=['Jeremy','Peter'],\n         address=dict(state='Queensland',country='Australia'))\nhl_md(json_to_xml(a, 'person'))\n\n&lt;person&gt;\n  &lt;surname&gt;Howard&lt;/surname&gt;\n  &lt;firstnames&gt;\n    &lt;item&gt;Jeremy&lt;/item&gt;\n    &lt;item&gt;Peter&lt;/item&gt;\n  &lt;/firstnames&gt;\n  &lt;address&gt;\n    &lt;state&gt;Queensland&lt;/state&gt;\n    &lt;country&gt;Australia&lt;/country&gt;\n  &lt;/address&gt;\n&lt;/person&gt;",
    "crumbs": [
      "xml source"
    ]
  },
  {
    "objectID": "xml.html#including-documents",
    "href": "xml.html#including-documents",
    "title": "xml source",
    "section": "Including documents",
    "text": "Including documents\nAccording to Anthropic, “it’s essential to structure your prompts in a way that clearly separates the input data from the instructions”. They recommend using the following format:\nHere are some documents for you to reference for your task:\n    \n&lt;documents&gt;\n&lt;document index=\"1\"&gt;\n&lt;source&gt;\n(URL, file name, hash, etc)\n&lt;/source&gt;\n&lt;document_content&gt;\n(the text content)\n&lt;/document_content&gt;\n&lt;/document&gt;\n&lt;/documents&gt;\nWe will create some small helper functions to make it easier to generate context in this format. Although it’s based on Anthropic’s recommendation, it’s likely to work well with other models too.\n\n\nExported source\ndoctype = namedtuple('doctype', ['source', 'content'])\n\n\nWe’ll use doctype to store our pairs.\n\n\nExported source\ndef _add_nls(s):\n    \"Add newlines to start and end of `s` if missing\"\n    if s[ 0]!='\\n': s = '\\n'+s\n    if s[-1]!='\\n': s = s+'\\n'\n    return s\n\n\nSince Anthropic’s example shows newlines before and after each tag, we’ll do the same.\n\nsource\n\nmk_doctype\n\n mk_doctype (content:str, source:Optional[str]=None)\n\nCreate a doctype named tuple\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncontent\nstr\n\nThe document content\n\n\nsource\nOptional\nNone\nURL, filename, etc; defaults to md5(content) if not provided\n\n\nReturns\nnamedtuple\n\n\n\n\n\n\n\nExported source\ndef mk_doctype(content:str,  # The document content\n           source:Optional[str]=None # URL, filename, etc; defaults to `md5(content)` if not provided\n          ) -&gt; namedtuple:\n    \"Create a `doctype` named tuple\"\n    if source is None: source = hashlib.md5(content.encode()).hexdigest()[:8]\n    return doctype(_add_nls(str(source).strip()), _add_nls(content.strip()))\n\n\nThis is a convenience wrapper to ensure that a doctype has the needed information in the right format.\n\ndoc = 'This is a sample'\nmk_doctype(doc)\n\ndoctype(source='\\nb8898fab\\n', content='\\nThis is a sample\\n')\n\n\n\nfrom fastcore.xml import xt\n\n\nsource\n\n\nmk_doc\n\n mk_doc (index:int, content:str, source:Optional[str]=None)\n\nCreate an xt format tuple for a single doc in Anthropic’s recommended format\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nindex\nint\n\nThe document index\n\n\ncontent\nstr\n\nThe document content\n\n\nsource\nOptional\nNone\nURL, filename, etc; defaults to md5(content) if not provided\n\n\nReturns\ntuple\n\n\n\n\n\n\n\nExported source\ndef mk_doc(index:int,  # The document index\n           content:str,  # The document content\n           source:Optional[str]=None # URL, filename, etc; defaults to `md5(content)` if not provided\n          ) -&gt; tuple:\n    \"Create an `xt` format tuple for a single doc in Anthropic's recommended format\"\n    dt = mk_doctype(content, source)\n    content = xt('document_content', dt.content)\n    source =  xt('source', dt.source)\n    return xt('document', source, content, index=index)\n\n\n\nsource\n\n\nmk_doc\n\n mk_doc (index:int, content:str, source:Optional[str]=None)\n\nCreate an xt format tuple for a single doc in Anthropic’s recommended format\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nindex\nint\n\nThe document index\n\n\ncontent\nstr\n\nThe document content\n\n\nsource\nOptional\nNone\nURL, filename, etc; defaults to md5(content) if not provided\n\n\nReturns\ntuple\n\n\n\n\n\n\n\nExported source\ndef mk_doc(index:int,  # The document index\n           content:str,  # The document content\n           source:Optional[str]=None # URL, filename, etc; defaults to `md5(content)` if not provided\n          ) -&gt; tuple:\n    \"Create an `xt` format tuple for a single doc in Anthropic's recommended format\"\n    dt = mk_doctype(content, source)\n    content = Document_content(dt.content)\n    source = Source(dt.source)\n    return Document(source, content, index=index)\n\n\nWe can now generate XML for one document in the suggested format:\n\ndt = mk_doctype(doc)\n\n\nprint(to_xml(mk_doc(1, doc)))\n\n&lt;document index=\"1\"&gt;\n  &lt;source&gt;\nb8898fab\n&lt;/source&gt;\n  &lt;document_content&gt;\nThis is a sample\n&lt;/document_content&gt;\n&lt;/document&gt;\n\n\n\n\nsource\n\n\ndocs_xml\n\n docs_xml (docs:list[str], sources:Optional[list]=None, prefix:bool=True)\n\nCreate an XML string containing docs in Anthropic’s recommended format\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndocs\nlist\n\nThe content of each document\n\n\nsources\nOptional\nNone\nURLs, filenames, etc; each one defaults to md5(content) if not provided\n\n\nprefix\nbool\nTrue\nInclude Anthropic’s suggested prose intro?\n\n\nReturns\nstr\n\n\n\n\n\n\n\nExported source\ndef docs_xml(docs:list[str],  # The content of each document\n             sources:Optional[list]=None,  # URLs, filenames, etc; each one defaults to `md5(content)` if not provided\n             prefix:bool=True # Include Anthropic's suggested prose intro?\n            )-&gt;str:\n    \"Create an XML string containing `docs` in Anthropic's recommended format\"\n    pre = 'Here are some documents for you to reference for your task:\\n\\n' if prefix else ''\n    if sources is None: sources = [None]*len(docs)\n    docs = (mk_doc(i+1, *o) for i,o in enumerate(zip(docs,sources)))\n    return pre + to_xml(Documents(docs))\n\n\nPutting it all together, we have our final XML format:\n\ndocs = [doc, 'And another one']\nsources = [None, 'doc.txt']\nprint(docs_xml(docs, sources))\n\nHere are some documents for you to reference for your task:\n\n&lt;documents&gt;\n  &lt;document index=\"1\"&gt;\n    &lt;source&gt;\nb8898fab\n&lt;/source&gt;\n    &lt;document_content&gt;\nThis is a sample\n&lt;/document_content&gt;\n  &lt;/document&gt;\n  &lt;document index=\"2\"&gt;\n    &lt;source&gt;\ndoc.txt\n&lt;/source&gt;\n    &lt;document_content&gt;\nAnd another one\n&lt;/document_content&gt;\n  &lt;/document&gt;\n&lt;/documents&gt;",
    "crumbs": [
      "xml source"
    ]
  },
  {
    "objectID": "xml.html#context-creation",
    "href": "xml.html#context-creation",
    "title": "xml source",
    "section": "Context creation",
    "text": "Context creation\nNow that we can generate Anthropic’s XML format, let’s make it easy for a few common cases.\n\nFile list to context\nFor generating XML context from files, we’ll just read them as text and use the file names as source.\n\nsource\n\n\nfiles2ctx\n\n files2ctx (fnames:list[typing.Union[str,pathlib.Path]], prefix:bool=True)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfnames\nlist\n\nList of file names to add to context\n\n\nprefix\nbool\nTrue\nInclude Anthropic’s suggested prose intro?\n\n\nReturns\nstr\n\nXML for LM context\n\n\n\n\n\nExported source\ndef files2ctx(\n    fnames:list[Union[str,Path]], # List of file names to add to context\n    prefix:bool=True # Include Anthropic's suggested prose intro?\n)-&gt;str: # XML for LM context\n    fnames = [Path(o) for o in fnames]\n    contents = [o.read_text() for o in fnames]\n    return docs_xml(contents, fnames, prefix=prefix)\n\n\n\nfnames = ['samples/sample_core.py', 'samples/sample_styles.css']\nhl_md(files2ctx(fnames))\n\nHere are some documents for you to reference for your task:\n\n&lt;documents&gt;\n  &lt;document index=\"1\"&gt;\n    &lt;source&gt;\nsamples/sample_core.py\n&lt;/source&gt;\n    &lt;document_content&gt;\nimport inspect\nempty = inspect.Parameter.empty\nmodels = &#x27;claude-3-opus-20240229&#x27;,&#x27;claude-3-sonnet-20240229&#x27;,&#x27;claude-3-haiku-20240307&#x27;\n&lt;/document_content&gt;\n  &lt;/document&gt;\n  &lt;document index=\"2\"&gt;\n    &lt;source&gt;\nsamples/sample_styles.css\n&lt;/source&gt;\n    &lt;document_content&gt;\n.cell { margin-bottom: 1rem; }\n.cell &gt; .sourceCode { margin-bottom: 0; }\n.cell-output &gt; pre { margin-bottom: 0; }\n&lt;/document_content&gt;\n  &lt;/document&gt;\n&lt;/documents&gt;\n\n\n\n\nFolder to context\n\nsource\n\n\nfolder2ctx\n\n folder2ctx (folder:Union[str,pathlib.Path], prefix:bool=True,\n             recursive:bool=True, symlinks:bool=True, file_glob:str=None,\n             file_re:str=None, folder_re:str=None,\n             skip_file_glob:str=None, skip_file_re:str=None,\n             skip_folder_re:str=None, func:callable=&lt;function join&gt;,\n             ret_folders:bool=False)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfolder\nUnion\n\nFolder name containing files to add to context\n\n\nprefix\nbool\nTrue\nInclude Anthropic’s suggested prose intro?\n\n\nrecursive\nbool\nTrue\nsearch subfolders\n\n\nsymlinks\nbool\nTrue\nfollow symlinks?\n\n\nfile_glob\nstr\nNone\nOnly include files matching glob\n\n\nfile_re\nstr\nNone\nOnly include files matching regex\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nskip_file_re\nstr\nNone\nSkip files matching regex\n\n\nskip_folder_re\nstr\nNone\nSkip folders matching regex,\n\n\nfunc\ncallable\njoin\nfunction to apply to each matched file\n\n\nret_folders\nbool\nFalse\nreturn folders, not just files\n\n\nReturns\nstr\n\nXML for Claude context\n\n\n\n\n\nExported source\n@delegates(globtastic)\ndef folder2ctx(\n    folder:Union[str,Path], # Folder name containing files to add to context\n    prefix:bool=True, # Include Anthropic's suggested prose intro?\n    **kwargs # Passed to `globtastic`\n)-&gt;str: # XML for Claude context\n    fnames = globtastic(folder, **kwargs)\n    return files2ctx(fnames, prefix=prefix)\n\n\n\nprint(folder2ctx('samples', prefix=False, file_glob='*.py'))\n\n&lt;documents&gt;\n  &lt;document index=\"1\"&gt;\n    &lt;source&gt;\nsamples/sample_core.py\n&lt;/source&gt;\n    &lt;document_content&gt;\nimport inspect\nempty = inspect.Parameter.empty\nmodels = &#x27;claude-3-opus-20240229&#x27;,&#x27;claude-3-sonnet-20240229&#x27;,&#x27;claude-3-haiku-20240307&#x27;\n&lt;/document_content&gt;\n  &lt;/document&gt;\n&lt;/documents&gt;",
    "crumbs": [
      "xml source"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "toolslm",
    "section": "",
    "text": "This is a work in progress…",
    "crumbs": [
      "toolslm"
    ]
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "toolslm",
    "section": "Install",
    "text": "Install\npip install toolslm",
    "crumbs": [
      "toolslm"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "toolslm",
    "section": "How to use",
    "text": "How to use\n\nContext creation\ntoolslm has some helpers to make it easier to generate XML context from files, for instance folder2ctx:\n\nprint(folder2ctx('samples', prefix=False, file_glob='*.py'))\n\n&lt;documents&gt;\n&lt;document index=\"1\"&gt;\n&lt;source&gt;\nsamples/sample_core.py\n&lt;/source&gt;\n&lt;document_content&gt;\nimport inspect\nempty = inspect.Parameter.empty\nmodels = 'claude-3-opus-20240229','claude-3-sonnet-20240229','claude-3-haiku-20240307'\n&lt;/document_content&gt;\n&lt;/document&gt;\n&lt;/documents&gt;\n\n\n\n\nXML helpers\nMany language models work well with XML inputs, but XML can be a bit clunky to work with manually. Therefore, toolslm includes a couple of more streamlined approaches for XML generation.\nAn XML node contains a tag, optional children, and optional attributes. xt creates a tuple of these three things, which we will use to general XML shortly. Attributes are passed as kwargs; since these might conflict with reserved words in Python, you can optionally add a _ prefix and it’ll be stripped off.\n\nxt('x-custom', ['hi'], _class='bar')\n\n('x-custom', ['hi'], {'class': 'bar'})\n\n\nClaudette has functions defined for some common HTML elements to create xt tuples more easily, including these:\n\nfrom toolslm.xml import div,img,h1,h2,p,hr,html\n\n\na = html([\n    p('This is a paragraph'),\n    hr(),\n    img(src='http://example.prg'),\n    div([\n        h1('This is a header'),\n        h2('This is a sub-header', style='k:v'),\n    ], _class='foo')\n])\na\n\n('html',\n [('p', 'This is a paragraph', {}),\n  ('hr', None, {}),\n  ('img', None, {'src': 'http://example.prg'}),\n  ('div',\n   [('h1', 'This is a header', {}),\n    ('h2', 'This is a sub-header', {'style': 'k:v'})],\n   {'class': 'foo'})],\n {})\n\n\nTo convert a tuple data structure created with xt and friends into XML, use to_xml, adding the hl parameter to optionally add syntax highlighting:\n\nto_xml(a, hl=True)\n\n&lt;html&gt;\n  &lt;p&gt;This is a paragraph&lt;/p&gt;\n  &lt;hr /&gt;\n  &lt;img src=\"http://example.prg\" /&gt;\n  &lt;div class=\"foo\"&gt;\n    &lt;h1&gt;This is a header&lt;/h1&gt;\n    &lt;h2 style=\"k:v\"&gt;This is a sub-header&lt;/h2&gt;\n  &lt;/div&gt;\n&lt;/html&gt;\n\n\nJSON doesn’t map as nicely to XML as the xt data structure, but for simple XML trees it can be convenient. The json_to_xml function handles that conversion:\n\na = dict(surname='Howard', firstnames=['Jeremy','Peter'],\n         address=dict(state='Queensland',country='Australia'))\nprint(json_to_xml(a, 'person'))\n\n&lt;person&gt;\n  &lt;surname&gt;Howard&lt;/surname&gt;\n  &lt;firstnames&gt;\n    &lt;item&gt;Jeremy&lt;/item&gt;\n    &lt;item&gt;Peter&lt;/item&gt;\n  &lt;/firstnames&gt;\n  &lt;address&gt;\n    &lt;state&gt;Queensland&lt;/state&gt;\n    &lt;country&gt;Australia&lt;/country&gt;\n  &lt;/address&gt;\n&lt;/person&gt;\n\n\nSee the xml source section for a walkthru of XML and document context generation functionality.",
    "crumbs": [
      "toolslm"
    ]
  }
]